{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ExampleCNN.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "private_outputs": true,
      "collapsed_sections": [
        "Tce3stUlHN0L"
      ],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/spaziochirale/CorsoPythonML/blob/master/ExampleCNN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "Tce3stUlHN0L"
      },
      "cell_type": "markdown",
      "source": [
        "##### Copyright 2018 The TensorFlow Authors.\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "tuOe1ymfHZPu",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#@title Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "# https://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "MfBg1C5NB3X0"
      },
      "cell_type": "markdown",
      "source": [
        "# Costruire una Convolutional Neural Network utilizzando gli Estimators\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "xHxb-dlhMIzW"
      },
      "cell_type": "markdown",
      "source": [
        "Il modulo `tf.layers` fornisce un'API di alto livello che semplifica la costruzione di Reti Neurali. \n",
        "In particolare mette a disposizione metodi che facilitano la creazioni di layers di tipo *dense*, cioè completamente connessi, e layer convoluzionali, permettendo l'aggiunta di funzioni di attivazioni specifiche e operazioni di *dropout*.\n",
        "In questo tutorial,\n",
        "viene spiegato come utilizzare `layers` per costruire una CNN da applicare al MNIST data set classico.\n",
        "\n",
        "![cifre manoscritte 0–9 dal  MNIST data set](https://www.tensorflow.org/images/mnist_0-9.png)\n",
        "\n",
        "Il [MNIST dataset](http://yann.lecun.com/exdb/mnist/) comprende 60,000\n",
        "esempi di training e 10,000  esempi di test di cifre 0–9 scritte a mano,\n",
        "formattate come matrici monocromatiche di 28x28-pixel."
      ]
    },
    {
      "metadata": {
        "id": "wTe-6uXpP2Ts",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Iniziamo\n",
        "\n",
        "Per prima cosa inseriamo le operazioni di import per i moduli TensorFlow:"
      ]
    },
    {
      "metadata": {
        "id": "6-tpguHLP6Rm",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from __future__ import absolute_import, division, print_function\n",
        "\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "\n",
        "tf.logging.set_verbosity(tf.logging.INFO)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "bUxWLCdTQexM",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "In questo notebook costruiremo la rete un passo alla volta. Il codice completo può essere\n",
        "[scaricato qui](https://www.tensorflow.org/code/tensorflow/examples/tutorials/layers/cnn_mnist.py)."
      ]
    },
    {
      "metadata": {
        "id": "4j5yyyDFQgSB",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Introduzione alle Convolutional Neural Networks\n",
        "\n",
        "Le reti CNN rappresentano lo stato dell'arte nell'ambito dei modelli per la classificazione di immagini.\n",
        "Una CNN applica una serie di filtri alla matrice di pixel d'origine per estrarre e apprendere le feature di più alto livello, che successivamente gli strati densi della rete utilizzeranno per effettuare la classificazione.\n",
        "\n",
        "Una rete CNN ha i seguenti componenti:\n",
        "\n",
        "*   **Convolutional layers**, che applicano il numero specifico di filtri all'immagine. Per ciascuna sotto-area, lo strato esegue un insieme di operazioni matematiche per produrre un singolo valore nella output feature map.\n",
        "    Gli strati convoluzionali utilizzano tipicamente una\n",
        "    [ReLU activation function](https://en.wikipedia.org/wiki/Rectifier_\\(neural_networks\\)) all'output per introdurre non linearità al modello.\n",
        "\n",
        "*   **Pooling layers**, che\n",
        "    [riducono la complessità dei dati](https://en.wikipedia.org/wiki/Convolutional_neural_network#Pooling_layer)\n",
        "   estratti dai layer convoluzionali con l'obiettivo di ridurre le dimensioni della\n",
        "    feature map e quindi del tempo di elaborazione. Un algoritmo di pooling molto usato è il max pooling, che estrae dalla feature map delle sotto-regioni    (ad esempio di 2x2-pixel), mantenendo solo il valore massimo e scartando tutti gli altri\n",
        "\n",
        "*   **Dense (fully connected) layers**, che eseguono la classificazione delle\n",
        "    features estratte dai layers convoluzionali e downsampled dai\n",
        "    pooling layers. In un dense layer, ogni nodo in di un layer è connesso ad\n",
        "    ogni nodo idel layer precedente.\n",
        "\n",
        "Solitamente una CNN è composta da uno stack di moduli convoluzionali che eseguono l'estrazione delle features. Ogni modulo è costituito da un layer convoluzionale seguito da un pooling layer. L'ultimo modulo convoluzionale è seguito da uno o più strati di tipo dense che effettuano la classificazione.\n",
        "L'ultimo strato dense della rete contiene tanti nodi quante sono le categorie che il modello è chiamato a prevedere. Tali nodi hanno una\n",
        "[softmax](https://en.wikipedia.org/wiki/Softmax_function) activation function per generare valori nell'intervallo 0–1 per ciascun nodo (la somma di tutti i nodi softmax è pari ad 1). Il valore può essere interpretato come la confidenza stimata dalla rete che l'immagine appartenga alla specifica categoria rappresentata dal nodo.\n",
        "\n",
        "Per un approfondimento si consulti [Convolutional Neural Networks for Visual Recognition course material](https://cs231n.github.io/convolutional-networks/)."
      ]
    },
    {
      "metadata": {
        "id": "j23E_Z0FQvZB",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Costruiamo il Classifier CNN per il MNIST Data set\n",
        "\n",
        "Nel nostro modello, utilizzeremo l'architettura seguente:\n",
        "\n",
        "1.  **Convolutional Layer #1**: Applica 32 filtri 5x5  (per estrarre aree di 5x5-pixel), con la ReLU activation function\n",
        "2.  **Pooling Layer #1**: Esegue il max pooling con un filtro 2x2 filter e passo (stride) di 2\n",
        "    (le regioni non si sovrappongono)\n",
        "3.  **Convolutional Layer #2**: Applica 64 filtri 5x5, con la ReLU activation\n",
        "    function\n",
        "4.  **Pooling Layer #2**: Identico al pooling layer #1\n",
        "5.  **Dense Layer #1**: 1,024 neuron1, con dropout regularization rate di 0.4\n",
        "    (probabilità di 0.4 che un dato elemento sarà eliminato durante il training)\n",
        "6.  **Dense Layer #2 (Logits Layer)**: 10 neuron1, uno per ciascun digit (0–9).\n",
        "\n",
        "Il modulo `tf.layers` contiene metodi per creare ciascuno dei layer elencati sopra:\n",
        "\n",
        "*   `conv2d()`. Costruisce un layer convoluzionale bidimensionale. Riceve come parametri il numero di filtri, il kernel size di ciascun filtro, il padding e la funzione di attivazione.\n",
        "*   `max_pooling2d()`. Costruisce un pooling layer bidimensionale che usa l'algoritmo di \n",
        "    max-pooling. Riceve come argomenti la dimensione dei filtri e lo stride.\n",
        "*   `dense()`. Costruisce un dense layer. Riceve come argomenti il numero di neuroni e l'activation\n",
        "    function.\n",
        "\n",
        "Ciascuno di questi metodi accetta come input un tensore e restituisce un tensore trasformato come output.\n",
        "In questo modo è semplice interconnettere i layer, utilizzando l'output del layer precedente come input del layer seguente.\n",
        "\n",
        "Per realizzare un Estimator in TensorFlow, è necessario scrivere una funzione `cnn_model_fn` in modo conforme all'interfaccia specificata per le API TensorFlow's Estimator (si veda [Creare l'Estimator](#create-the-estimator)). \n",
        "Questa funzione riceve come argomenti le feature del data set MNIST, le relative labels, e il parametro *mode* (il cui valore assumerà uno degli stati indicati da `tf.estimator.ModeKeys`: `TRAIN`, `EVAL`, `PREDICT`);\n",
        "Questa funzione configura la CNN; e restituisce le predictions, il valore della funzione loss, e il riferimento all'operazione di training.\n",
        "Il codice della funzione è il seguente:"
      ]
    },
    {
      "metadata": {
        "id": "gMR-_3rkRKPa",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def cnn_model_fn(features, labels, mode):\n",
        "  \"\"\"Model function for CNN.\"\"\"\n",
        "  # Input Layer\n",
        "  input_layer = tf.reshape(features[\"x\"], [-1, 28, 28, 1])\n",
        "\n",
        "  # Convolutional Layer #1\n",
        "  conv1 = tf.layers.conv2d(\n",
        "      inputs=input_layer,\n",
        "      filters=32,\n",
        "      kernel_size=[5, 5],\n",
        "      padding=\"same\",\n",
        "      activation=tf.nn.relu)\n",
        "\n",
        "  # Pooling Layer #1\n",
        "  pool1 = tf.layers.max_pooling2d(inputs=conv1, pool_size=[2, 2], strides=2)\n",
        "\n",
        "  # Convolutional Layer #2 and Pooling Layer #2\n",
        "  conv2 = tf.layers.conv2d(\n",
        "      inputs=pool1,\n",
        "      filters=64,\n",
        "      kernel_size=[5, 5],\n",
        "      padding=\"same\",\n",
        "      activation=tf.nn.relu)\n",
        "  pool2 = tf.layers.max_pooling2d(inputs=conv2, pool_size=[2, 2], strides=2)\n",
        "\n",
        "  # Dense Layer\n",
        "  pool2_flat = tf.reshape(pool2, [-1, 7 * 7 * 64])\n",
        "  dense = tf.layers.dense(inputs=pool2_flat, units=1024, activation=tf.nn.relu)\n",
        "  dropout = tf.layers.dropout(\n",
        "      inputs=dense, rate=0.4, training=mode == tf.estimator.ModeKeys.TRAIN)\n",
        "\n",
        "  # Logits Layer\n",
        "  logits = tf.layers.dense(inputs=dropout, units=10)\n",
        "\n",
        "  predictions = {\n",
        "      # Generate predictions (for PREDICT and EVAL mode)\n",
        "      \"classes\": tf.argmax(input=logits, axis=1),\n",
        "      # Add `softmax_tensor` to the graph. It is used for PREDICT and by the\n",
        "      # `logging_hook`.\n",
        "      \"probabilities\": tf.nn.softmax(logits, name=\"softmax_tensor\")\n",
        "  }\n",
        "\n",
        "  if mode == tf.estimator.ModeKeys.PREDICT:\n",
        "    return tf.estimator.EstimatorSpec(mode=mode, predictions=predictions)\n",
        "\n",
        "  # Calculate Loss (for both TRAIN and EVAL modes)\n",
        "  loss = tf.losses.sparse_softmax_cross_entropy(labels=labels, logits=logits)\n",
        "\n",
        "  # Configure the Training Op (for TRAIN mode)\n",
        "  if mode == tf.estimator.ModeKeys.TRAIN:\n",
        "    optimizer = tf.train.GradientDescentOptimizer(learning_rate=0.001)\n",
        "    train_op = optimizer.minimize(\n",
        "        loss=loss,\n",
        "        global_step=tf.train.get_global_step())\n",
        "    return tf.estimator.EstimatorSpec(mode=mode, loss=loss, train_op=train_op)\n",
        "\n",
        "  # Add evaluation metrics (for EVAL mode)\n",
        "  eval_metric_ops = {\n",
        "      \"accuracy\": tf.metrics.accuracy(\n",
        "          labels=labels, predictions=predictions[\"classes\"])\n",
        "  }\n",
        "  return tf.estimator.EstimatorSpec(\n",
        "      mode=mode, loss=loss, eval_metric_ops=eval_metric_ops)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "b7z8qC9FRSLB",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Nelle sezioni seguenti, in cui ciascun titolo corrisponde a ciascuno dei blocchi di codice scritti sopra, viene specificato in maggiore dettaglio il significato del codice utilizzato per definire ciascun layer e le modalità utilizzate per calcolare il loss, configurare l'operazione di training e generare le previsioni. \n"
      ]
    },
    {
      "metadata": {
        "id": "sFBXEYRlRUWu",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Input Layer\n",
        "\n",
        "I metodi del modulo `layers` per creare gli strati convoluzionali e di pooling per i dati bidimensionali delle immagini richiedono che i tensori di input abbiano uno *shape* di\n",
        "<code>[<em>batch_size</em>, <em>image_height</em>, <em>image_width</em>,\n",
        "<em>channels</em>]</code> di default. Questo comportamento può essere modificato utilizzando il parametro\n",
        "<code><em>data_format</em></code>; definito nel modo seguente:\n",
        "\n",
        "*   `batch_size` —Dimensione del sottoinsieme di esempi da utilizzare quando si esegue il gradient descent durante la fase di training.\n",
        "*   `image_height` —Altezza delle immagini di esempio.\n",
        "*   `image_width` —Larghezza delle immagini di esempio.\n",
        "*   `channels` —Numero dei canali di colore nelle immagini di esempio. Per immagini a colori, il numero di canali è 3 (red, green, blue). Per immagini monocromatiche il numero di canali è soltanto 1 (black).\n",
        "*   `data_format` —Una stringa di valore `channels_last` (default) oppure `channels_first`.\n",
        "      `channels_last` corrisponde ad inputs con shape\n",
        "      `(batch, ..., channels)` mentre `channels_first` corrisponde a\n",
        "      inputs con shape `(batch, channels, ...)`.\n",
        "\n",
        "Nel nostro caso, il dataset MNIST è composto da immagini monocromatiche di 28x28 pixel, pertanto lo shape atteso per il nostro input layer è <code>[<em>batch_size</em>, 28, 28,\n",
        "1]</code>.\n",
        "\n",
        "Per convertire la nostra feature map (`features`) di input a questo shape, possiamo eseguire la seguente operazione `reshape`:\n",
        "\n",
        "```\n",
        "input_layer = tf.reshape(features[\"x\"], [-1, 28, 28, 1])\n",
        "```\n",
        "\n",
        "Si noti che abbiamo indicato `-1` per il batch size. Questa notazione indica che tale dimensione debba essere calcolata dinamicamente in base al numero di valori di input in\n",
        "`features[\"x\"]`, mantenendo costanti tutte le altre dimensioni. Questo permette di trattare `batch_size` come un iperparametro utilizzabile per effettuare il tuning. \n",
        "Ad esempio, se alimentiamo la rete in batch di 5, `features[\"x\"]` conterrà\n",
        "3,920 valori (un valore per ciascun pixel in ciascuna immagine), e `input_layer` avrà uno shape di `[5, 28, 28, 1]`. Analogamente, se forniamo esempi in batch di\n",
        "100, `features[\"x\"]` conterrà 78,400 valori, e `input_layer` avrà uno\n",
        "shape di `[100, 28, 28, 1]`."
      ]
    },
    {
      "metadata": {
        "id": "iU8Jr1_JRiKA",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Convolutional Layer #1\n",
        "\n",
        "Nel nostro primo strato convoluzionale vogliamo applicare all'input 32 filtri 5X5, seguiti da una funzione di attivazione ReLU. Possiamo utilizzare il metodo `conv2d()` del modulo\n",
        "`layers` in questo modo:\n",
        "\n",
        "```\n",
        "conv1 = tf.layers.conv2d(\n",
        "    inputs=input_layer,\n",
        "    filters=32,\n",
        "    kernel_size=[5, 5],\n",
        "    padding=\"same\",\n",
        "    activation=tf.nn.relu)\n",
        "```\n",
        "\n",
        "Il parametro `inputs` specifica il tensore di input, che deve avere shape di\n",
        "<code>[<em>batch_size</em>, <em>image_height</em>, <em>image_width</em>,\n",
        "<em>channels</em>]</code>. Connettiamo il primo convolutional layer\n",
        "all' `input_layer`, che ha shape <code>[<em>batch_size</em>, 28, 28,\n",
        "1]</code>.\n",
        "\n",
        "Nota: `conv2d()` al contrario, si aspetta uno shape di `[<em>batch_size</em>, <em>channels</em>, <em>image_height</em>, <em>image_width</em>]` quando viene indicato il parametro `data_format=channels_first`.\n",
        "\n",
        "Il parametro `filters` specifica il numero di filtri da applicare (nel nostro caso 32), e\n",
        "`kernel_size` specifica la dimensione dei filtri come `[<em>height</em>,\n",
        "<em>width</em>]</code> (nel nostro caso <code>[5, 5]`).\n",
        "\n",
        "<p class=\"tip\"><b>TIP:</b> Nel caso in cui filter height e width abbiano lo stesso valore è possibile specificare un\n",
        "singolo intero per <code>kernel_size</code>—ad esempio <code>kernel_size=5</code>.</p>\n",
        "\n",
        "Il parametro `padding` specifica uno dei seguenti valori\n",
        "(case-insensitive): `valid` (default) oppure `same`. \n",
        "Nel nostro caso abbiamo indicato `padding=same` per specificare che il tensore di output deve avere le stesse dimensioni del tensore di input,\n",
        "TensorFlow aggiunge zeri agli estremi del tensore di input per mantenere height e width di 28. (Senza padding,\n",
        "una convoluzione 5x5 su un tensore 28x28 produrrebbe un tensore 24x24).\n",
        "\n",
        "Il parametro `activation` specifica la funzione di attivazione da applicare all'output della convoluzione. \n",
        "Nel nostro caso abbiamo specificato una attivazione ReLU utilizzando il valore\n",
        "`tf.nn.relu`.\n",
        "\n",
        "Il tensore di output prodotto nel nostro caso da `conv2d()` ha uno shape di\n",
        "<code>[<em>batch_size</em>, 28, 28, 32]</code>:  Le dimensioni height e width\n",
        "hanno gli stessi valori dell'input, ma con 32 canali che mantengono gli output da ciascuno dei filtri."
      ]
    },
    {
      "metadata": {
        "id": "8qzx1ZMFRqt_",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Pooling Layer #1\n",
        "\n",
        "A questo punto possiamo connettere il nostro primo strato di pooling al layer convoluzionale che abbiamo appena creato.\n",
        "Possiamo utilizzare il metodo `max_pooling2d()` del modulo `layers` per costruire uno strato che effettua il max pooling con un filtro 2x2 e uno stride di 2:\n",
        "\n",
        "```\n",
        "pool1 = tf.layers.max_pooling2d(inputs=conv1, pool_size=[2, 2], strides=2)\n",
        "```\n",
        "\n",
        "Anche in questo caso, `inputs` specifica il tensore di input che ha uno shape di\n",
        "<code>[<em>batch_size</em>, <em>image_height</em>, <em>image_width</em>,\n",
        "<em>channels</em>]</code>. Nel nostro caso, il tensore di input è `conv1`, cioè l'output del primo strato convoluzionale, che ha uno shape di <code>[<em>batch_size</em>,\n",
        "28, 28, 32]</code>.\n",
        "\n",
        "Nota: Così come <code>conv2d()</code>, anche <code>max_pooling2d()</code> si aspetterà uno shape di <code>[<em>batch_size</em>, <em>channels</em>, \n",
        "<em>image_height</em>, <em>image_width</em>]</code> se viene utilizzato il parametro\n",
        "<code>data_format=channels_first</code>.\n",
        "\n",
        "Il parametro `pool_size` specifica la dimensione del filtro di max pooling pari a\n",
        "<code>[<em>height</em>, <em>width</em>]</code> (nel nostro caso `[2, 2]`). Se entrambe le dimensioni hanno lo stesso valore è possibile specificare un unico numero intero (ad esempio\n",
        "`pool_size=2`).\n",
        "\n",
        "Il parametro `strides` specifica la dimensione del passo. Nel nostro caso abbiamo impostato uno stride\n",
        "di 2, che indica che le aree estratte dal filtro devono essere separate da 2 pixel sia in altezza che in larghezza (per un filtro 2x2 questo comporta che nessuna regione si sovrappone alle altre). È possibile impostare passi differenti per altezza e larghezza specificando una tupla o una lista (ad esempio `stride=[3, 6]`).\n",
        "\n",
        "Il nostro tensore di output prodotto da `max_pooling2d()` (`pool1`) ha uno shape di\n",
        "<code>[<em>batch_size</em>, 14, 14, 32]</code>: il filtro 2x2 riduce le dimensioni height e width, ciascuna del 50%."
      ]
    },
    {
      "metadata": {
        "id": "xXej53NlRzFh",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Convolutional Layer #2 e Pooling Layer #2\n",
        "\n",
        "Possiamo quindi connettere un secondo strato convoluzionale seguito da un secondo strato di pooling nello stesso modo utilizzando \n",
        "`conv2d()` e `max_pooling2d()` .\n",
        "Per il secondo layer convoluzionale abbiamo configurato 64 5x5 filtri con funzione di attivazioneReLU, e per il pooling layer #2 abbiamo utilizzato le stesse specifiche del pooling layer #1 (un filtro max pooling 2x2 con stride di 2):\n",
        "\n",
        "```\n",
        "conv2 = tf.layers.conv2d(\n",
        "    inputs=pool1,\n",
        "    filters=64,\n",
        "    kernel_size=[5, 5],\n",
        "    padding=\"same\",\n",
        "    activation=tf.nn.relu)\n",
        "\n",
        "pool2 = tf.layers.max_pooling2d(inputs=conv2, pool_size=[2, 2], strides=2)\n",
        "```\n",
        "\n",
        "Si noti che il convolutional layer #2 riceve come input il tensore di output del primo pooling\n",
        "layer (`pool1`) e produce in output il tensore `conv2`. `conv2`\n",
        "ha uno shape di <code>[<em>batch_size</em>, 14, 14, 64]</code>, stesse dimensioni in altezza e larghezza di `pool1` (in conseguenza del parametro `padding=\"same\"`), e 64 canali a seguito dei 64\n",
        "filtri che sono stati applicati.\n",
        "\n",
        "Pooling layer #2 riceve `conv2` come input, fornendo `pool2` come output. `pool2`\n",
        "ha uno shape di <code>[<em>batch_size</em>, 7, 7, 64]</code> (riduzione del 50% per height e width dai valori di `conv2`)."
      ]
    },
    {
      "metadata": {
        "id": "jjmLqVP7R7z6",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Dense Layer\n",
        "\n",
        "Dopo i due stadi convoluzionali + pooling, aggiungiamo uno strato denso con 1.024 neuroni funzione di attivazione ReLU.\n",
        "Questa sezione effettuerà la classificazione delle features estratte dalla parte convoluzionale.\n",
        "Prima di connettere lo strato denso è necessario \"appiattire\" la feature map output di `pool2`, che è in forma bidimensionale\n",
        "con shape <code>[<em>batch_size</em>,\n",
        "<em>features</em>]</code>, ottenendo un tensore di una dimensione + il batch size:\n",
        "\n",
        "```\n",
        "pool2_flat = tf.reshape(pool2, [-1, 7 * 7 * 64])\n",
        "```\n",
        "\n",
        "Nell'operazione `reshape()`  `-1` implica che la dimensione *`batch_size`*\n",
        "sarà calcolata dinamicamente in base alla dimensione dell'input. Ogni campione ha 7 (`pool2` height) * 7 (`pool2` width) * 64\n",
        "(`pool2` channels) feature, e noi vogliamo per  `features` una dimensione di  7 * 7 * 64 (3136 in totale). Il tensore di output, `pool2_flat`, ha shape\n",
        "<code>[<em>batch_size</em>, 3136]</code>.\n",
        "\n",
        "Possiamo quindi utilizzare il metodo `dense()` di `layers` per connettere lo strato di classificazione:\n",
        "\n",
        "```\n",
        "dense = tf.layers.dense(inputs=pool2_flat, units=1024, activation=tf.nn.relu)\n",
        "```\n",
        "\n",
        "Il parametro `inputs` specifica il tensore di input cioè la nostra feature map dopo l'operazione di flattening,\n",
        "`pool2_flat`. Il parametro `units` specifica il numero di neuroni del dense\n",
        "layer (1.024). Il parametro `activation` specifica la activation function; anche in questo caso,\n",
        "abbiamo usato `tf.nn.relu` per aggiungere una funzione ReLU.\n",
        "\n",
        "Allo scopo di prevenire fenomeni di overfitting e ottimizzare le prestazioni del modello, abbiamo deciso di utilizzare la strategia di dropout regularization\n",
        "applicata al dense layer, attraverso la chiamata al metodo `dropout` del modulo `layers`:\n",
        "\n",
        "```\n",
        "dropout = tf.layers.dropout(\n",
        "    inputs=dense, rate=0.4, training=mode == tf.estimator.ModeKeys.TRAIN)\n",
        "```\n",
        "\n",
        "Come sempre, `inputs` indica il tensore di input, che è il tensore di output del\n",
        "dense layer (`dense`).\n",
        "\n",
        "Il parametro `rate` specifica il grado di dropout; in questo caso  `0.4`, che significa che il\n",
        "40% degli elementi saranno eliminati durante il training.\n",
        "\n",
        "Il parametro `training` è un valore booleano che specifica se il modello è chiamato o meno in modalità di training; il dropout viene eseguito solo se il valore di\n",
        "`training` è `True`. All'interno della chiamata, viene quindi verificato se il valore di `mode` passato alla funzione\n",
        "`cnn_model_fn` è `TRAIN`.\n",
        "\n",
        "Il tensore di output `dropout` ha shape <code>[<em>batch_size</em>, 1024]</code>."
      ]
    },
    {
      "metadata": {
        "id": "rzUcwkCZSTF7",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Logits Layer\n",
        "\n",
        "L'ultimo layer della nostra rete e un layer di tipo logits. Questo strato restituisce i valori complessivi della previsione effettuata dalla rete.\n",
        "Viene creato un dense layer con 10 neuron1 (uno per\n",
        "ciascuna classe target 0–9), con funzione di attivazione lineare (il default):\n",
        "\n",
        "```\n",
        "logits = tf.layers.dense(inputs=dropout, units=10)\n",
        "```\n",
        "\n",
        "L'output finale della CNN, `logits`, ha shape `[batch_size, 10]`."
      ]
    },
    {
      "metadata": {
        "id": "y3uJ0V1KSakc",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Generare le Previsioni {#generate_predictions}\n",
        "\n",
        "Il logits layer del nostro modello restituisce le previsioni in forma di valori raw  in un tensore di shape\n",
        "<code>[<em>batch_size</em>, 10]</code>. \n",
        "Convertiamo questi valori\n",
        "raw in due diversi formati che possano essere restituiti dalla model function:\n",
        "\n",
        "*   La **predicted class** per ciascun campione: una cifra nel range 0–9.\n",
        "*   Le **probabilities** per ciascuna probabile categoria di ciascun campione: la probabilità che il campione rappresenti uno 0, un 1, un 2, etc.\n",
        "\n",
        "Dato un campione, la previsione della rete è indicata dalla cifra con la maggiore probabilità. possiamo calcolarla con il metodo `tf.argmax`:\n",
        "\n",
        "```\n",
        "tf.argmax(input=logits, axis=1)\n",
        "```\n",
        "\n",
        "Il parametro `input` specifica il tensore dal quale estrarre i valori massimi —nel nostro caso `logits`. Il parametro `axis` specifica gli assi del tensore `input`\n",
        "lungo il quale trovare il valore massimo. Nel nostro caso, vogliamo trovare il valore più grande lungo la dimensione con indice 1, che corrisponde alle nostre previsioni.\n",
        "(Si ricordi che il tensore logits ha shape <code>[<em>batch_size</em>,\n",
        "10]</code>).\n",
        "\n",
        "Possiamo derivare le probabilità dal logits layer applicando la funzione di attivazione softmax utilizzando `tf.nn.softmax`:\n",
        "\n",
        "```\n",
        "tf.nn.softmax(logits, name=\"softmax_tensor\")\n",
        "```\n",
        "\n",
        "Nota: Abbiamo usato il parametro `name` per battezzare in modo esplicito questa operazione `softmax_tensor`, in questo modo sarà possibile referenziarla quando imposteremo il logging per i valori softmax nella sezione [\"Impostare un Logging Hook\"](#set-up-a-logging-hook)).\n",
        "\n",
        "Le previsioni vengono quindi compilate in un dizionario e restituite tramite un oggetto `EstimatorSpec`:\n",
        "\n",
        "```\n",
        "predictions = {\n",
        "    \"classes\": tf.argmax(input=logits, axis=1),\n",
        "    \"probabilities\": tf.nn.softmax(logits, name=\"softmax_tensor\")\n",
        "}\n",
        "if mode == tf.estimator.ModeKeys.PREDICT:\n",
        "  return tf.estimator.EstimatorSpec(mode=mode, predictions=predictions)\n",
        "```"
      ]
    },
    {
      "metadata": {
        "id": "f2ks_tqSSucg",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Calcolo del Loss {#calculating-loss}\n",
        "\n",
        "Sia nella fase di training che nella fase di valutazione della bontà del modello, è necessario definire una\n",
        "[loss function](https://en.wikipedia.org/wiki/Loss_function)\n",
        "che misuri quanto accurate siano le prevsioni del modello in relazione alle categorie target.\n",
        "Per problemi di classificazione come il MNIST,\n",
        "[cross entropy](https://en.wikipedia.org/wiki/Cross_entropy) è la metrica di loss usata nella maggior parte dei casi. \n",
        "il codice seguente calcola la funzione cross entropy quando la rete è eseguita in modalità `TRAIN` o `EVAL`:\n",
        "\n",
        "```\n",
        "loss = tf.losses.sparse_softmax_cross_entropy(labels=labels, logits=logits)\n",
        "```\n",
        "\n",
        "il tensore `labels` contiene una lista di indici di previsione per il campione passato, ad esempio. `[1,\n",
        "9, ...]`. `logits` contiene gli output lineari dell'ultimo layer. \n",
        "\n",
        "`tf.losses.sparse_softmax_cross_entropy`, calcola la softmax crossentropy\n",
        "da questi due input in modo efficiente."
      ]
    },
    {
      "metadata": {
        "id": "YgE7Ll3pS2FG",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Configurare l'operazione di Training\n",
        "\n",
        "Configuriamo ora il nostro modello in modo da ottimizzare il valore del loss calcolato nel modo indicato in precedenza, durante il training. Useremo un parametro di learning rate pari a 0.001 e il metodo\n",
        "[stochastic gradient descent](https://en.wikipedia.org/wiki/Stochastic_gradient_descent)\n",
        "come algoritmo di ottimizzazione:\n",
        "\n",
        "```\n",
        "if mode == tf.estimator.ModeKeys.TRAIN:\n",
        "  optimizer = tf.train.GradientDescentOptimizer(learning_rate=0.001)\n",
        "  train_op = optimizer.minimize(\n",
        "      loss=loss,\n",
        "      global_step=tf.train.get_global_step())\n",
        "  return tf.estimator.EstimatorSpec(mode=mode, loss=loss, train_op=train_op)\n",
        "```"
      ]
    },
    {
      "metadata": {
        "id": "rEJPnXAzS6m9",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Nota: Per i dettagli su come configurare una operazione di training per le model function degli  Estimator si veda [\"Defining the training op for the model\"](../../guide/custom_estimators.md#defining-the-training-op-for-the-model) nel tutorial [\"Creating Estimations in tf.estimator\"](../../guide/custom_estimators.md)."
      ]
    },
    {
      "metadata": {
        "id": "QQuGDWvHTAib",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Aggiungere le metriche di valutazione\n",
        "\n",
        "Per definire la metrica accuracy nel nostro modello abbiamo definito il dizionario `eval_metric_ops`  quando la funzione è chiamata in EVAL\n",
        "mode nel modo seguente:\n",
        "\n",
        "```\n",
        "eval_metric_ops = {\n",
        "    \"accuracy\": tf.metrics.accuracy(\n",
        "        labels=labels, predictions=predictions[\"classes\"])\n",
        "}\n",
        "return tf.estimator.EstimatorSpec(\n",
        "    mode=mode, loss=loss, eval_metric_ops=eval_metric_ops)\n",
        "```"
      ]
    },
    {
      "metadata": {
        "id": "Y2Bwe-AdTRzX",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "<a id=\"train_eval_mnist\"></a>\n",
        "## Training e Valutazione del Classificatore CNN MNIST\n",
        "\n",
        "Una volta scritta la model function del modello MNIST CNN siamo pronti per addestrare e testare la rete."
      ]
    },
    {
      "metadata": {
        "id": "6EC9aOY2TTLU",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Caricare i dati di Training e Test\n",
        "\n",
        "Il codice seguente carica i due dataset di training e test:"
      ]
    },
    {
      "metadata": {
        "id": "ccobb0qETV-S",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Load training and eval data\n",
        "((train_data, train_labels),\n",
        " (eval_data, eval_labels)) = tf.keras.datasets.mnist.load_data()\n",
        "\n",
        "train_data = train_data/np.float32(255)\n",
        "train_labels = train_labels.astype(np.int32)  # not required\n",
        "\n",
        "eval_data = eval_data/np.float32(255)\n",
        "eval_labels = eval_labels.astype(np.int32)  # not required"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "8l84-IxSTZnO",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "I dati di training delle feature (i valori raw dei pixel per le 55.000 immagini di cifre scritte a mano) e le relative label (valori 0–9 corrispondenti a ciascuna immagine) sono memorizzati nei due vettori di tipo [numpy\n",
        "arrays](https://docs.scipy.org/doc/numpy/reference/generated/numpy.array.html)\n",
        " `train_data` e `train_labels`. \n",
        "Analogamente i dati di test (10.000 immagini) e le label relative sono memorizzati in `eval_data`\n",
        "e `eval_labels`."
      ]
    },
    {
      "metadata": {
        "id": "S2_Isc7kTa45",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Creare l'Estimator {#create-the-estimator}\n",
        "\n",
        "A questo punto possiamo creare un `Estimator` (una classe TensorFlow per effettuare ad alto livello il training, la valutazione del modello e le previsioni) per il nostro modello:"
      ]
    },
    {
      "metadata": {
        "id": "yjC6HdwZTdg4",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Create the Estimator\n",
        "mnist_classifier = tf.estimator.Estimator(\n",
        "    model_fn=cnn_model_fn, model_dir=\"/tmp/mnist_convnet_model\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "f78EBcg7TfTU",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Il parametro `model_fn` specifica la model function da utilizzare per le fasi di training,\n",
        "valutazione, e previsione; abbiamo valorizzato il parametro con la `cnn_model_fn` creata nella sezione\n",
        "[\"Costruire il Classificatore CNN per il dataset MNIST\"](#building-the-cnn-mnist-classifier) Il parametro\n",
        "`model_dir` specifica la directory dove i dati del modello (checkpoints) saranno salvati (nel nostro esempio abbiamo usato `/tmp/mnist_convnet_model`, ma il lettore può scegliere una qualunque altra destinazione sul proprio file system).\n",
        "\n",
        "Nota: Per maggiori dettagli sulle API TensorFlow `Estimator` si rimanda al tutorial [Creating Estimators in tf.estimator](../../guide/custom_estimators.md)."
      ]
    },
    {
      "metadata": {
        "id": "_6ow7hVYTm3f",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Impostare un Logging Hook {#set_up_a_logging_hook}\n",
        "\n",
        "Poiché la fase di addestramento di una CNN può essere molto lunga, è opportuno impostare una attività di logging per tracciare l'avanzamento e i progressi effettuati durante il training.\n",
        "Possiamo utilizzare la classe TensorFlow `tf.train.SessionRunHook` per creare un\n",
        "`tf.train.LoggingTensorHook`\n",
        "che effettuerà il log dei valori di probabilità dal softmax layer della nostra CNN:"
      ]
    },
    {
      "metadata": {
        "id": "S6T10kssTpdz",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Set up logging for predictions\n",
        "tensors_to_log = {\"probabilities\": \"softmax_tensor\"}\n",
        "\n",
        "logging_hook = tf.train.LoggingTensorHook(\n",
        "    tensors=tensors_to_log, every_n_iter=50)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "RZdtZ6JQTsmg",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Memorizziamo il dizionario dei tensori che intendiamo loggare in `tensors_to_log`. Ciascuna key rappresenta la label di nostra scelta che sarà riportata nell'output del log, e la label corrispondente è il nome di un `Tensor` nel grafo TensorFlow. Nel nostro caso, le\n",
        "`probabilities` possono essere trovate nel `softmax_tensor`, il nome che abbiamo attribuito in precedenza all'operazione softmax\n",
        "quando abbiamo generato le probabilità in `cnn_model_fn`.\n",
        "\n",
        "Nota: se non viene assegnato un nome esplicito tramite il parametro `name`, TensorFlow assegnerà un nome di default all'operazione. Per scoprire il nome assegnato all'operazione si può visualizzare il grafo utilizzando la [TensorBoard](../../guide/graph_viz.md)) o abilitare il [TensorFlow Debugger (tfdbg)](../../guide/debugger.md).\n",
        "\n",
        "A questo punto creiamo `LoggingTensorHook`, passando `tensors_to_log` al parametro\n",
        "`tensors`. Abbiamo impostato `every_n_iter=50`, per specificare che le probabilità devono essere loggate ogni 50 step."
      ]
    },
    {
      "metadata": {
        "id": "brVs1dRMT0NM",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Training del Modello\n",
        "\n",
        "Per addestrare il modello occorre definire una `train_input_fn`\n",
        "e richiamare il metodo `train()` sull'oggetto `mnist_classifier`. \n",
        "Nella chiamata `numpy_input_fn` passiamo le feature e le label dei dati di training rispettivamente come\n",
        "`x` (dizionario) e `y`. Impostiamo un `batch_size` di `100`.\n",
        "`num_epochs=None` indica che il modello svolgerà il training finché il numero specificato di step non sarà raggiunto. Abbiamo anche impostato `shuffle=True` per mescolare casualmente i dati di training. \n",
        "A questo punto possiamo lanciare uno step di training ed effettuare il log dell'output:"
      ]
    },
    {
      "metadata": {
        "id": "h-dewpleT2sk",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Train the model\n",
        "train_input_fn = tf.estimator.inputs.numpy_input_fn(\n",
        "    x={\"x\": train_data},\n",
        "    y=train_labels,\n",
        "    batch_size=100,\n",
        "    num_epochs=None,\n",
        "    shuffle=True)\n",
        "\n",
        "# train one step and display the probabilties\n",
        "mnist_classifier.train(\n",
        "    input_fn=train_input_fn,\n",
        "    steps=1,\n",
        "    hooks=[logging_hook])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "gyNSE3e-14Lq",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "A questo punto, evitando di effettuare il log di ciascuno step, impostiamo `steps=1000` per effettuare un training più lungo, ma ancora per un tempo adatto a questo esempio. \n",
        "Il training di reti CNN è molto costoso in termini computazionali.  20.000 step è un valore che potrebbe fornire una accuratezza maggiore. "
      ]
    },
    {
      "metadata": {
        "id": "cri6zqcf2IXY",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "mnist_classifier.train(input_fn=train_input_fn, steps=1000)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "4bQdkLMeUE5U",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Valutare il Modello\n",
        "\n",
        "Una volta effettuato il training possiamo richiamare il metodo `evaluate` per valutare l'accuratezza raggiunta sui dati di test utilizzando le metriche definite nel parametro `eval_metric_ops` della `model_fn`.\n"
      ]
    },
    {
      "metadata": {
        "id": "I0RGiqd0UF0N",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "eval_input_fn = tf.estimator.inputs.numpy_input_fn(\n",
        "    x={\"x\": eval_data},\n",
        "    y=eval_labels,\n",
        "    num_epochs=1,\n",
        "    shuffle=False)\n",
        "\n",
        "eval_results = mnist_classifier.evaluate(input_fn=eval_input_fn)\n",
        "print(eval_results)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "JIBVID6dUIXT",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Per definire `eval_input_fn`, abbiamo impostato `num_epochs=1`, in modo che il modello effettui una iterazione sul set di dati e restituisca i risultati. \n",
        "`shuffle=False` imposta l'iterazione in modo sequenziale sui dati."
      ]
    },
    {
      "metadata": {
        "id": "htmLZ-zEUZZk",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Approfondimenti\n",
        "\n",
        "Per maggiori dettagli sui TensorFlow Estimators e le CNNs in TensorFlow, si consiglia:\n",
        "\n",
        "*   [Creating Estimators in tf.estimator](../../guide/custom_estimators.md)\n",
        "    Introduzione a TensorFlow Estimator API. Configurare Estimator, scrivere una model function, calcolare loss, e\n",
        "    definire una training op.\n",
        "*   [Advanced Convolutional Neural Networks](../../tutorials/images/deep_cnn.md) Costruire un MNIST CNN classification model\n",
        "    *senza estimator* utilizzando API TensorFlow di basso livello."
      ]
    }
  ]
}