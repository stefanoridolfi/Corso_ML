{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "TF-Basic.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "private_outputs": true,
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/spaziochirale/CorsoPythonML/blob/master/TF_Basic.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "MhoQ0WE77laV",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "##### Copyright 2018 The TensorFlow Authors."
      ]
    },
    {
      "metadata": {
        "id": "_ckMIh7O7s6D",
        "colab_type": "code",
        "cellView": "form",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#@title Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "# https://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "vasWnqRgy1H4",
        "colab_type": "code",
        "cellView": "form",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#@title MIT License\n",
        "#\n",
        "# Copyright (c) 2017 François Chollet\n",
        "#\n",
        "# Permission is hereby granted, free of charge, to any person obtaining a\n",
        "# copy of this software and associated documentation files (the \"Software\"),\n",
        "# to deal in the Software without restriction, including without limitation\n",
        "# the rights to use, copy, modify, merge, publish, distribute, sublicense,\n",
        "# and/or sell copies of the Software, and to permit persons to whom the\n",
        "# Software is furnished to do so, subject to the following conditions:\n",
        "#\n",
        "# The above copyright notice and this permission notice shall be included in\n",
        "# all copies or substantial portions of the Software.\n",
        "#\n",
        "# THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\n",
        "# IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\n",
        "# FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL\n",
        "# THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\n",
        "# LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING\n",
        "# FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER\n",
        "# DEALINGS IN THE SOFTWARE."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "jYysdyb-CaWM",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Esempio di Rete Neurale con Tensor Flow: basic classification"
      ]
    },
    {
      "metadata": {
        "id": "lDSz6VrOdmR-",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "In questa lezione costruiremo e addestreremo una rete neurale per la classificazione di immagini di indumenti come, sneaker, magliette o camice.\n",
        "L'esempio è basato su uno dei tutorial standard proposti sul sito Tensor Flow e utilizza le API di alto livello del package [tf.keras](https://www.tensorflow.org/guide/keras) della libreria TensorFlow.\n",
        "\n",
        "Keras, come il resto del TensorFlow, è una API di livello industriale che richiede un certo tempo per il suo apprendimento, pertanto non saranno sempre chiari tutti i dettagli, e, anche se cercheremo di fornire le spiegazioni man mano che l'esempio procede, il lettore è invitato a mantenere una visione generale del problema senza preoccuparsi troppo dei dettagli.\n",
        "\n",
        "La porzione di codice che segue mostra l'importazione delle librerie necessarie."
      ]
    },
    {
      "metadata": {
        "id": "dzLKpmZICaWN",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from __future__ import absolute_import, division, print_function\n",
        "\n",
        "# TensorFlow and tf.keras\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "\n",
        "# Helper libraries\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "print(tf.__version__)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "yR0EdgrLCaWR",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Importiamo il dataset Fashion MNIST che sarà utilizzato in questa lezione"
      ]
    },
    {
      "metadata": {
        "id": "DLdCchMdCaWQ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Utilizzeremo il dataset [Fashion MNIST](https://github.com/zalandoresearch/fashion-mnist) che contiene 70.000 immagini monocromatiche (in scala di grigio) relative a 10 categorie di capi d'abbigliamento.\n",
        "\n",
        "Ciascun'immagine è una bitmap di 28 X 28 pixel che raffigura in bassa risoluzione uno specifico prodotto. \n",
        "\n",
        "La figura seguente mostra alcune bitmap del dataset.\n",
        "\n",
        "<table>\n",
        "  <tr><td>\n",
        "    <img src=\"https://tensorflow.org/images/fashion-mnist-sprite.png\"\n",
        "         alt=\"Fashion MNIST sprite\"  width=\"600\">\n",
        "  </td></tr>\n",
        "  <tr><td align=\"center\">\n",
        "    <b>Figura 1.</b> <a href=\"https://github.com/zalandoresearch/fashion-mnist\">Esempi Fashion-MNIST</a> (by Zalando, MIT License).<br/>&nbsp;\n",
        "  </td></tr>\n",
        "</table>\n",
        "\n",
        "\n",
        "Il dataset Fashion MNIST è stato creato da *Zalando Research* come dataset alternativo al celebre, ma oramai abusato, dataset [MNIST](http://yann.lecun.com/exdb/mnist/) divenuto una sorta di *Hello World* nell'ambito dei programmi di visione artificiale. Il datast MNIST classico contiene immagini analoghe relative alle cifre da 0 a 9 scritte con calligrafia manuale.\n",
        "\n",
        "L'impiego del Fashion MNIST rappresenta un'alternativa molto più interessante e complessa da risolvere. Entrambi i dataset sono sufficientemente piccoli da poter gestire la fase di training su un PC in pochi minuti e rappresentano un ottimo punto di partenza in ambito didattico.\n",
        "\n",
        "Utilizzeremo 60.000 immagini per addestrare la rete e 10.000 immagini per valutare il livello di generalizzazione raggiunto dalla rete.\n",
        "Il dataset è incluso nella distribuzione della libreria TensorFlow ed è quindi sufficiente importare e caricare i dati, senza doversi preoccupare ulteriormente dell'acquisizione della fonte dei dati.\n"
      ]
    },
    {
      "metadata": {
        "id": "7MqDQO0KCaWS",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "fashion_mnist = keras.datasets.fashion_mnist\n",
        "\n",
        "(train_images, train_labels), (test_images, test_labels) = fashion_mnist.load_data()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "t9FDsUlxCaWW",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Il metodo *load_data()* dell'oggetto *fashion_mnist* restituisce quattro oggetti, suddivisi in due tuple, di tipo *array NumPy*. \n",
        "\n",
        "Un *array NumPy* è una struttura dati definita nell'ambito della libreria *numpy* molto utilizzata nella *data science*. Per il momento possiamo immaginarli come semplici vettori multidimensionali di elementi senza preoccuparci ulteriormente delle effettive proprietà dell'oggetto.\n",
        "\n",
        "\n",
        "* Gli array `train_images` e `train_labels` costituiscono il *training set*—che sarà utilizzato per addestrare la rete.\n",
        "* Una volta addestrato, il modello sarà testato utilizzando il *test set* costituito dagli array `test_images` e `test_labels`.\n",
        "\n",
        "Le immagini sono array NumPy di dimensione  28x28, i cui valori dei pixel variano da 0 a 255.  \n",
        "\n",
        "Le etichette *labels* sono array di numeri interi i cui valori variano da 0 a 9. \n",
        "\n",
        "Questi valori corrispondono alla *categoria* del capo di abbigliamento raffigurato nell'immagine, secondo la seguente tabella:\n",
        "\n",
        "\n",
        "<table>\n",
        "  <tr>\n",
        "    <th>Label</th>\n",
        "    <th>Categoria</th> \n",
        "  </tr>\n",
        "  <tr>\n",
        "    <td>0</td>\n",
        "    <td>T-shirt/top</td> \n",
        "  </tr>\n",
        "  <tr>\n",
        "    <td>1</td>\n",
        "    <td>Pantalone</td> \n",
        "  </tr>\n",
        "    <tr>\n",
        "    <td>2</td>\n",
        "    <td>Pullover</td> \n",
        "  </tr>\n",
        "    <tr>\n",
        "    <td>3</td>\n",
        "    <td>Abito</td> \n",
        "  </tr>\n",
        "    <tr>\n",
        "    <td>4</td>\n",
        "    <td>Cappotto</td> \n",
        "  </tr>\n",
        "    <tr>\n",
        "    <td>5</td>\n",
        "    <td>Sandalo</td> \n",
        "  </tr>\n",
        "    <tr>\n",
        "    <td>6</td>\n",
        "    <td>Camicia</td> \n",
        "  </tr>\n",
        "    <tr>\n",
        "    <td>7</td>\n",
        "    <td>Sneaker</td> \n",
        "  </tr>\n",
        "    <tr>\n",
        "    <td>8</td>\n",
        "    <td>Borsa</td> \n",
        "  </tr>\n",
        "    <tr>\n",
        "    <td>9</td>\n",
        "    <td>Stivaletto</td> \n",
        "  </tr>\n",
        "</table>\n",
        "\n",
        "Ciascuna immagine è messa in corrispondenza ad una singola etichetta (label).\n",
        "\n",
        "Poiché il dataset non include i nome delle categorie, ma solo l'indice numerico da 0 a 9, decidiamo di memorizzare tali nomi in una lista per poi poterli utilizzare per etichettare in modo più comprensibile i grafici che andremo a stampare durante l'esercizio:\n"
      ]
    },
    {
      "metadata": {
        "id": "IjnLH5S2CaWx",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class_names = ['T-shirt/top', 'Pantalone', 'Pullover', 'Abito', 'Cappotto', \n",
        "               'Sandalo', 'Camicia', 'Sneaker', 'Borsa', 'Stivaletto']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Brm0b_KACaWX",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Exploriamo i nostri dati\n",
        "\n",
        "Lanciamo ora alcune istruzioni di utilità per esplorare il formato del nostro dataset prima di procedere con la costruzione del modello, cioè della rete, e con la fase di addestramento.\n",
        "\n",
        "Il comando seguente mostra che il dataset è costituito da 60.000 immagini, con ciascuna immagine costituita da 28X28 pixel. Il metodo *shape* restituisce una tupla che contiene le dimensioni del *tensore*.\n"
      ]
    },
    {
      "metadata": {
        "id": "zW5k_xz1CaWX",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "train_images.shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "cIAcvQqMCaWf",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Analogamente utilizziamo questa volta l'operatore *len()* per mostrare che il training set contiene 60.000 label:"
      ]
    },
    {
      "metadata": {
        "id": "TRFYHB2mCaWb",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "len(train_labels)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "YSlYxFuRCaWk",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Ciascuna label è un numero intero tra 0 e 9:"
      ]
    },
    {
      "metadata": {
        "id": "XKnCTHz4CaWg",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "train_labels"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "TMPI88iZpO2T",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "10.000 images sono contenute nel test set e, come in precedenza, ciascuna immagine è composta da 28 x 28 pixel:"
      ]
    },
    {
      "metadata": {
        "id": "2KFnYlcwCaWl",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "test_images.shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "rd0A0Iu0CaWq",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Il test set contiene 10.000 etichette:"
      ]
    },
    {
      "metadata": {
        "id": "iJmPr5-ACaWn",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "len(test_labels)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ES6uQoLKCaWr",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Preprocessamento dei dati\n",
        "\n",
        "Per una maggiore efficienza computazionale è sempre raccomandabile di procedere ad un preprocessamento dei dati, normalizzandoli secondo opportuni criteri.\n",
        "\n",
        "Nel nostro caso se osserviamo la prima immagine del training set vediamo che i valori dei pixel cadono all'interno dell'intervallo 0-255.\n",
        "\n",
        "Possiamo visualizzare graficamente questo fatto utilizzando opportune funzioni del package *PyPlot* che abbiamo già incontrato nella precedente lezione:\n"
      ]
    },
    {
      "metadata": {
        "id": "m4VEw8Ud9Quh",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "plt.figure()\n",
        "plt.imshow(train_images[0])\n",
        "plt.colorbar()\n",
        "plt.grid(False)\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Wz7l27Lz9S1P",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Una normalizzazione molto comune consiste nello scalare l'intervallo dei valori di input nell'ambito dell'intervallo 0-1.\n",
        "\n",
        "Per far questo è sufficiente dividere ciascun valore per 255.\n",
        "\n",
        "È importante che entrambi i set di training e test vengano preprocessati nello stesso identico modo.\n",
        "\n",
        "Grazie alla potenza espressiva del Python l'operazione è pressoché immediata:\n"
      ]
    },
    {
      "metadata": {
        "id": "bW5WzIPlCaWv",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "train_images = train_images / 255.0\n",
        "\n",
        "test_images = test_images / 255.0"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Ee638AlnCaWz",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "A questo punto possiamo provare a disegnare le prime 25 immagini del training set riportando il nome della categoria del prodotto sotto ciascuna immagine.\n",
        "\n",
        "Verifichiamo quindi che i dati siano nel formato corretto in modo da essere pronti a costruire la rete e procedere con l'addestramento.\n",
        "\n",
        "Anche in questo caso utilizziamo le funzioni messe a disposizione del modulo *PyPlot*. Per approfondimenti il lettore è invitato a consultare la reference del package *PyPlot*\n"
      ]
    },
    {
      "metadata": {
        "id": "oZTImqg_CaW1",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(10,10))\n",
        "for i in range(25):\n",
        "    plt.subplot(5,5,i+1)\n",
        "    plt.xticks([])\n",
        "    plt.yticks([])\n",
        "    plt.grid(False)\n",
        "    plt.imshow(train_images[i], cmap=plt.cm.binary)\n",
        "    plt.xlabel(class_names[train_labels[i]])\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "59veuiEZCaW4",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Costruiamo il modello\n",
        "\n",
        "Per costruire una rete neurale attraverso la libreria Keras, si procede configurando i singoli strati del modello e successivamente *compilando* il modello. \n"
      ]
    },
    {
      "metadata": {
        "id": "Gxg1XGm0eOBy",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Configurazione dei layer\n",
        "\n",
        "Il layer è l'elemento base di una rete neurale.\n",
        "\n",
        "Nei modelli di deep learning i layer sono collegati gli uni agli altri.\n",
        "\n",
        "Keras offre dei modelli di layer, come ad esempio `tf.keras.layers.Dense`, che permettono di configurare strati corrispondenti a modelli ben noti nella teoria delle reti neurali e che contengono tutti i parametri che verranno valorizzati a seguito della fase di addestramento.\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "9ODch-OFCaW4",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model = keras.Sequential([\n",
        "    keras.layers.Flatten(input_shape=(28, 28)),\n",
        "    keras.layers.Dense(128, activation=tf.nn.relu),\n",
        "    keras.layers.Dense(10, activation=tf.nn.softmax)\n",
        "])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "gut8A_7rCaW6",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Il primo layer della rete, `tf.keras.layers.Flatten`, trasforma il formato delle immagini da un array bidimensionale (di 28 X 28 pixel), ad un array monodimensionale di 28 * 28 = 784 pixel. \n",
        "\n",
        "Il layer di *flattening* non ha pesi che vengono modificati durante il training. Semplicemente cambia la forma dell'input attraverso un trasferimento diretto del valore in input verso l'output.\n",
        "\n",
        "Dopo lo strato di allineamento, la rete è composta da una sequenza di due layer `tf.keras.layers.Dense`. Si tratta di strati in cui tutti i neuroni sono connessi. Il primo layer `Dense` ha 128 nodi (o neuroni). Il secondo (e ultimo) layer è un layer  *softmax* con 10 nodi che restituisce un array di 10 punteggi di probabilità, la cui somma è pari ad 1. Il valore in output di ciascuno di questi neuroni rappresenta la probabilità che l'immagine in input sia appartenente alla categoria rappresentata da quel nodo.\n",
        "\n",
        "### Compilazione del modello\n",
        "\n",
        "Prima che il modello sia pronto per la fase di training è necessario effettuare ancora alcune configurazioni. Nella piattaforma Keras queste configurazioni vengono svolte attraverso l'operazione di *compilazione* svolta invocando il metodo *compile()*.\n",
        "\n",
        "* *Loss function* —Serve per misurare l'accuratezza del modello durante la fase di addestramento. L'obiettivo è quello di minimizzare questa funzione in modo da guidare il modello verso la corretta impostazioni dei parametri (pesi).\n",
        "* *Optimizer* —Rappresenta la funzione attraverso la quale i pesi vengono modificati in base al valore dell'input fornito e alla valutazione della funzione *loss*.\n",
        "* *Metrics* —Viene utilizzata per monitorare la fase di training e la fase di test. Nel nostro esempio utilizzeremo *accuracy*, valutata come la percentuale di immagini correttamente classificata.\n",
        "\n",
        "Grazie alla libreria TensorFlow non dobbiamo preoccuparci dei dettagli implementativi delle funzioni matematiche che sono alla base del calcolo del *loss* e della strategia di ottimizzazione, ma possiamo limitarci a richiamare metodi noti in letteratura e già implementati nelle API."
      ]
    },
    {
      "metadata": {
        "id": "Lhan11blCaW7",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model.compile(optimizer='adam', \n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "qKF6uW-BCaW-",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Addestramento del Modello\n",
        "\n",
        "La fase di training della rete è composta dai seguenti passi:\n",
        "\n",
        "1. Alimentare la rete con i dati di training—nel nostro caso, gli array `train_images` e `train_labels`.\n",
        "2. Attendere che il modello apprenda la corretta associazione tra immagini e *lable*.\n",
        "3. Sperimentare le prestazioni del modello alimentandolo con l'insieme dei dati di test—nel nostro caso l'array `test_images` . In particolare verificheremo che le immagini siano associate correttamente alle etichette contenute nell'array `test_labels`. \n",
        "\n",
        "Il training viene avviato invocando il metodo `model.fit` —il termine \"fit\" è tipico del machine learning basato su metodi statistici. Il metodo riceve in inpute i due array e il numero di *epoche* da utilizzare per l'addestramento:"
      ]
    },
    {
      "metadata": {
        "id": "xvwvpA64CaW_",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model.fit(train_images, train_labels, epochs=5)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "W3ZVOhugCaXA",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Man mano che procede il training, vengono visualizzati sullo schermo i valori della funzione loss e l'accuratezza (metrica *accuracy*).\n",
        "\n",
        "Questo modello raggiunge un'accuratezza di circa l'88% (0,88) sui dati di training.\n"
      ]
    },
    {
      "metadata": {
        "id": "oEw4bZgGCaXB",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Valutare l'accuratezza\n",
        "\n",
        "Per valutare la bontà del modello occorre misurare la metrica di accuratezza sul dataset di test, composto da dati che non sono mai stati sottoposti alla rete in fase di training. Solo in questo modo potremo stimare quanto  la rete abbia realmente appreso in modo generalizzato.\n",
        "\n",
        "A tale scopo invochiamo il metodo `evaluate()` passando come parametri gli array `test_images` e `test_labels`."
      ]
    },
    {
      "metadata": {
        "id": "VflXLEeECaXC",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "test_loss, test_acc = model.evaluate(test_images, test_labels)\n",
        "\n",
        "print('Test accuracy:', test_acc)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "yWfgsmVXCaXG",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Come si può vedere, l'accuratezza misurata sui dati di test è inferiore all'accuratezza misurata durante il training.\n",
        "\n",
        "Questo è un esempio di *overfitting*. La rete in pratica ha ben memorizzato i dati di training ma non ha ancora ben generalizzato la sua capacità di classificare dati che non ha mai visto.\n",
        "\n",
        "Nel nostro caso le performance sono comunque accettabili. Esistono tecniche per gestire e prevenire questo problema.\n"
      ]
    },
    {
      "metadata": {
        "id": "xsoS7CPDCaXH",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Effettuare previsioni\n",
        "\n",
        "Una volta che la rete è stata addestrata, questa può essere utilizzata per effettuare previsioni.\n",
        "\n",
        "È quindi sufficiente invocare il metodo `predict()` fornendo come parametro un array di dati. Il metodo è strutturato per gestire batch di dati, ma ovviamente è possibile passare in input un solo dato, creando un array con un solo campione.\n",
        "\n",
        "Possiamo provare ad invocarlo utilizzando come esempio l'array `test_images`.\n"
      ]
    },
    {
      "metadata": {
        "id": "Gl91RPhdCaXI",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "predictions = model.predict(test_images)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "x9Kk1voUCaXJ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Il metodo predict() restituisce un array di previsioni. Proviamo quindi a stampare la prima previsione, quella corrispondente alla prima immagine fornita in input.\n"
      ]
    },
    {
      "metadata": {
        "id": "3DmJEUinCaXK",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "predictions[0]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "-hw1hgeSCaXN",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Ciascuna previsione è a sua volta un array di 10 valori. Ciascun valore indica la probabilità che l'immagine di input appartenga alla categoria corrispondente a quell'indice.\n",
        "\n",
        "Se vogliamo estrarre la lable corrispondente al valore di probabilità più alto, possiamo usare la funzione `argmax()` del package NumPy.\n"
      ]
    },
    {
      "metadata": {
        "id": "qsqenuPnCaXO",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "np.argmax(predictions[0])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "E51yS7iCCaXO",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Il modello è maggiormente confidente che l'immagine sia uno stivaletto, cioè `class_name[9]`. \n",
        "\n",
        "Nel nostro caso possiamo verificare quale sia la lable corretta dall'array `test_lable`.\n"
      ]
    },
    {
      "metadata": {
        "id": "Sd7Pgsu6CaXP",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "test_labels[0]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ygh2yYC972ne",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Possiamo creare un grafico per visualizzare l'insieme dei 10 canali."
      ]
    },
    {
      "metadata": {
        "id": "DvYmmrpIy6Y1",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def plot_image(i, predictions_array, true_label, img):\n",
        "  predictions_array, true_label, img = predictions_array[i], true_label[i], img[i]\n",
        "  plt.grid(False)\n",
        "  plt.xticks([])\n",
        "  plt.yticks([])\n",
        "  \n",
        "  plt.imshow(img, cmap=plt.cm.binary)\n",
        "\n",
        "  predicted_label = np.argmax(predictions_array)\n",
        "  if predicted_label == true_label:\n",
        "    color = 'blue'\n",
        "  else:\n",
        "    color = 'red'\n",
        "  \n",
        "  plt.xlabel(\"{} {:2.0f}% ({})\".format(class_names[predicted_label],\n",
        "                                100*np.max(predictions_array),\n",
        "                                class_names[true_label]),\n",
        "                                color=color)\n",
        "\n",
        "def plot_value_array(i, predictions_array, true_label):\n",
        "  predictions_array, true_label = predictions_array[i], true_label[i]\n",
        "  plt.grid(False)\n",
        "  plt.xticks([])\n",
        "  plt.yticks([])\n",
        "  thisplot = plt.bar(range(10), predictions_array, color=\"#777777\")\n",
        "  plt.ylim([0, 1]) \n",
        "  predicted_label = np.argmax(predictions_array)\n",
        " \n",
        "  thisplot[predicted_label].set_color('red')\n",
        "  thisplot[true_label].set_color('blue')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "d4Ov9OFDMmOD",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Osserviamo l'immagine 0, le previsioni e l'array di previsioni.\n"
      ]
    },
    {
      "metadata": {
        "id": "HV5jw-5HwSmO",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "i = 0\n",
        "plt.figure(figsize=(6,3))\n",
        "plt.subplot(1,2,1)\n",
        "plot_image(i, predictions, test_labels, test_images)\n",
        "plt.subplot(1,2,2)\n",
        "plot_value_array(i, predictions,  test_labels)\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Ko-uzOufSCSe",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "i = 12\n",
        "plt.figure(figsize=(6,3))\n",
        "plt.subplot(1,2,1)\n",
        "plot_image(i, predictions, test_labels, test_images)\n",
        "plt.subplot(1,2,2)\n",
        "plot_value_array(i, predictions,  test_labels)\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "kgdvGD52CaXR",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Effettuiamo un grafico con diverse immagini e le relative previsioni.\n",
        "Le previsioni corrette sono di colore blu quelle errate di colore rosso.\n",
        "I numeri forniscono le percentuali di confidenza per la lable stimata. Si osservi che anche nel caso in cui la rete stimi una elevata confidenza per una certa *lable*, questa può essere errata.\n"
      ]
    },
    {
      "metadata": {
        "id": "hQlnbqaw2Qu_",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Plot the first X test images, their predicted label, and the true label\n",
        "# Color correct predictions in blue, incorrect predictions in red\n",
        "num_rows = 5\n",
        "num_cols = 3\n",
        "num_images = num_rows*num_cols\n",
        "plt.figure(figsize=(2*2*num_cols, 2*num_rows))\n",
        "for i in range(num_images):\n",
        "  plt.subplot(num_rows, 2*num_cols, 2*i+1)\n",
        "  plot_image(i, predictions, test_labels, test_images)\n",
        "  plt.subplot(num_rows, 2*num_cols, 2*i+2)\n",
        "  plot_value_array(i, predictions, test_labels)\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "R32zteKHCaXT",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Proviamo ora ad utilizzare la rete addestrata per effettuare una previsione utilizzando una sola immagine.\n"
      ]
    },
    {
      "metadata": {
        "id": "yRJ7JU7JCaXT",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Grab an image from the test dataset\n",
        "img = test_images[0]\n",
        "\n",
        "print(img.shape)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "vz3bVp21CaXV",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Come già detto, i modelli `tf.keras` sono progettati per effettuare previsioni su *batch*, o collezioni, di esempi, forniti in blocco. Pertanto, se vogliamo utilizzare una sola immagine, questa deve essere comunque inserita in una lista."
      ]
    },
    {
      "metadata": {
        "id": "lDFh5yF_CaXW",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Add the image to a batch where it's the only member.\n",
        "img = (np.expand_dims(img,0))\n",
        "\n",
        "print(img.shape)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "EQ5wLTkcCaXY",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Effettuiamo la previsione per l'immagine:"
      ]
    },
    {
      "metadata": {
        "id": "o_rzNSdrCaXY",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "predictions_single = model.predict(img)\n",
        "\n",
        "print(predictions_single)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "6Ai-cpLjO-3A",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "plot_value_array(0, predictions_single, test_labels)\n",
        "_ = plt.xticks(range(10), class_names, rotation=45)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "cU1Y2OAMCaXb",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "`model.predict` restituisce una lista di liste, una lista per ogni singola immagine del batch fornito. Estraiamo quindi la previsione per l'unica immagine di cui è costituito il batch:"
      ]
    },
    {
      "metadata": {
        "id": "2tRmdq_8CaXb",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "np.argmax(predictions_single[0])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "YFc2HbEVCaXd",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Ovviamente, come già visto, la previsione è 9."
      ]
    }
  ]
}